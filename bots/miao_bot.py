from bots.base import BotBase
import json
import re


class MiaoBot(BotBase):
    interval = 60 * 60  # æ¯å°æ—¶æ‰§è¡Œä¸€æ¬¡
    file_prefix = "miaoaaaaa-Telegram-"
    output_folder = "apps"
    output_prefix = "apps"
    min_files_required = 3

    def extract_info_from_file(self, file_path):
        """ä»miaoaaaaaæ–‡ä»¶ä¸­æå–ä¿¡æ¯ï¼Œåªä¿ç•™æœ‰ç”¨çš„å†…å®¹"""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                article = json.load(f)

            # æ¸…ç†æ ‡é¢˜ä¸­çš„emojiç­‰ç‰¹æ®Šå­—ç¬¦
            title = article.get("title", "æ— æ ‡é¢˜")
            title = re.sub(r"ğŸ–¼|ğŸ—£|ğŸ·ï¸|ğŸ‘‰|ğŸš¬|ğŸ”¥|âºï¸|ğŸ‰|ğŸ|ğŸ‘", "", title)

            # æå–ä½œè€…ä¿¡æ¯
            author = article.get("author", "")

            # ä»æè¿°ä¸­æå–çº¯æ–‡æœ¬å†…å®¹
            description = self.clean_html(article.get("description", ""))

            # è¿‡æ»¤æ‰å¹¿å‘Šå†…å®¹
            if "çƒŸä¸š" in title or "çƒŸä¸š" in description:
                return None

            # æå–ä¸‹è½½é“¾æ¥
            download_link = ""
            link_match = re.search(r"ä¸‹è½½åœ°å€ï¼š?(https?://\S+)", description)
            if not link_match:
                link_match = re.search(r"é“¾æ¥ï¼š?(https?://\S+)", description)
            if link_match:
                download_link = link_match.group(1)

            # æå–æ ‡ç­¾
            tags = []
            tag_matches = re.findall(r"#(\w+)", description)
            if tag_matches:
                tags = tag_matches

            # ç§»é™¤é¢‘é“ã€æŠ•ç¨¿ç­‰ä¿¡æ¯
            description = re.sub(r"é¢‘é“.*?(?=\n|$)", "", description)
            description = re.sub(r"ç¾¤èŠ.*?(?=\n|$)", "", description)
            description = re.sub(r"æŠ•ç¨¿.*?(?=\n|$)", "", description)
            description = re.sub(r"åˆä½œ.*?(?=\n|$)", "", description)

            # ç§»é™¤å¤šä½™çš„ç©ºè¡Œå’Œç©ºæ ¼
            description = re.sub(r"\n\s*\n", "\n\n", description).strip()

            # æ ¼å¼åŒ–è¾“å‡º
            info = f"æ ‡é¢˜ï¼š{title.strip()}\n"
            if author:
                info += f"ä½œè€…ï¼š{author}\n"
            if download_link:
                info += f"ä¸‹è½½é“¾æ¥ï¼š{download_link}\n"
            if tags:
                info += f"æ ‡ç­¾ï¼š{', '.join(tags)}\n"
            info += f"æè¿°ï¼š{description}\n"

            return info
        except Exception as e:
            self.logger.error(f"æå–miaoaaaaaæ–‡ä»¶ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None

    def generate_title_prompt(self, article_content):
        """ç”Ÿæˆåº”ç”¨æ¨èæ ‡é¢˜çš„æç¤ºè¯"""
        return f"""
        ä½ ç°åœ¨æ˜¯ä¸€ä¸ªåº”ç”¨æ¨èå…¬ä¼—å·ç¼–è¾‘ï¼Œéœ€è¦æ ¹æ®ä»¥ä¸‹å†…å®¹ç”Ÿæˆä¸€ä¸ªå¸å¼•äººçš„æ ‡é¢˜ï¼Œè¦èƒ½å¢åŠ ç‚¹å‡»é‡ï¼š
        
        æ–‡ç« å†…å®¹: {article_content}
        
        è¯·ç”Ÿæˆä¸€ä¸ªå…³äºAppæ¨èã€å®ç”¨è½¯ä»¶å·¥å…·çš„å¸å¼•äººæ ‡é¢˜ã€‚æ ‡é¢˜åº”å½“ç®€æ´æ˜äº†ï¼Œçªå‡ºè½¯ä»¶çš„æ ¸å¿ƒä»·å€¼å’Œç‰¹ç‚¹ï¼Œå¸å¼•ç”¨æˆ·ä¸‹è½½å°è¯•ã€‚
        """

    def generate_article_prompt(self, articles_info):
        """ç”Ÿæˆåº”ç”¨æ¨èæ–‡ç« çš„æç¤ºè¯"""
        return f"""
        ä½ ç°åœ¨æ˜¯ä¸€ä¸ªåº”ç”¨æ¨èå…¬ä¼—å·ç¼–è¾‘ï¼Œéœ€è¦æ ¹æ®ä»¥ä¸‹å‡ ç¯‡æ–‡ç« çš„ä¿¡æ¯æ•´åˆç”Ÿæˆä¸€ç¯‡è½¯ä»¶æ¨èå…¬ä¼—å·æ–‡ç« ï¼š
        
        æ–‡ç« é›†åˆ: {articles_info}
        
        è¯·ç”Ÿæˆä¸€ç¯‡å…³äºå®ç”¨Appå’Œè½¯ä»¶å·¥å…·çš„æ¨èæ–‡ç« ï¼Œè¦æ±‚ï¼š
        1. æŒ‰è½¯ä»¶ç±»å‹åˆ†ç±»ï¼ˆå¦‚æ•ˆç‡å·¥å…·ã€ç”Ÿæ´»åº”ç”¨ã€è®¾è®¡è½¯ä»¶ã€å¼€å‘å·¥å…·ç­‰ï¼‰
        2. æ¯ä¸ªåº”ç”¨ä»‹ç»è¦ç®€æ´æ˜äº†ï¼Œçªå‡ºå…¶æ ¸å¿ƒåŠŸèƒ½å’Œä½¿ç”¨åœºæ™¯
        3. è¯´æ˜é€‚ç”¨å¹³å°ï¼ˆå¦‚iOSã€Androidã€Windowsã€macOSç­‰ï¼‰
        4. é‡ç‚¹ä»‹ç»åº”ç”¨çš„ç‰¹è‰²åŠŸèƒ½å’Œä¼˜åŠ¿
        5. ä¿ç•™ä¸‹è½½é“¾æ¥ï¼Œæ–¹ä¾¿è¯»è€…è·å–
        6. é€‚å½“æ·»åŠ ä¸€äº›ä½¿ç”¨æŠ€å·§æˆ–ä¸ªäººè¯„ä»·
        7. æ–‡æœ«å¯ä»¥æ€»ç»“è¿™äº›åº”ç”¨çš„å…±åŒç‰¹ç‚¹æˆ–æ¨èç†ç”±
        
        ç”Ÿæˆä¸€ç¯‡å®ç”¨æ€§å¼ºã€èƒ½å¸®åŠ©è¯»è€…å‘ç°ä¼˜è´¨åº”ç”¨çš„æ–‡ç« ã€‚
        """
